# CHAPTER FOUR

### Analysis and Finding

```{r}
#| label: fig-Time Series And Decompostion
#| fig-cap: "Time Series And Decompostion"
#| fig-subcap:
#|   - "Stationary Signal"
#|   - "Decompostion Of The Series"
#| layout-ncol: 2
#| column: page-right
# Convert data to time series.
Time_Series <- ts(data = Time_Series$mean_evi, start = c(2001, 1), end = c(2019, 11), frequency = 12)
plot(Time_Series)


Time_Series <- if(na.cnt > 0){imputeTS::na_kalman(Time_Series, model = "auto.arima", smooth = T)} else {
    Time_Series
}
plot(Time_Series)


tdx.dcp <- stl(Time_Series, s.window = 'periodic')
plot(tdx.dcp)

Tt <- trendcycle(tdx.dcp)
St <- seasonal(tdx.dcp)
Rt <- remainder(tdx.dcp)
# plot(Tt)
# plot(St)
plot(Rt)
```
Before building an ARIMA model we checked that if the series is stationary. That is, we needed to be determined that the time series is constant in mean and variance are constant and not dependent on time.Here, we look at a couple of methods for checking stationarity. If the time series is provided with seasonarity, a trend, or a change point in the mean or variance, then the influences need to be removed or accounted for. Augmented Dickey--Fuller (ADF) t-statistic test to find if the series has a unit root (a series with a trend line will have a unit root and result in a large p-value).

```{r}
#| label: fig-ACF
#| fig-cap: "ACF Plot and PACF plot analysis for sample between 2000 and 2020:"
#| fig-subcap:
#|   - "Stationary Signal"
#|   - "Trend Signal"
#| layout-ncol: 2
#| column: page-right
# The Stationary Signal and ACF
plot(Rt,col= "red", main = "Stationary Signal")
acf(Rt, lag.max = length(Rt),
    xlab = "lag", ylab = 'ACF', main = '')

#The Trend Signal anf ACF

plot(Tt,col= "red",main = "Trend Signal")
acf(Tt, lag.max = length(Tt),
    xlab = "lag", ylab = "ACF", main = '')
```
**Discuss:**Shows the initial ACF plot and we can see that before lag 25 almost all are significant and having no trend it needs to be differentiated before performing any analysis. Clearly the seasonality is visible even in the ACF plot.

**Dickey-Fuller Test and Plot**

```{r,warning=FALSE,message=FALSE}
tseries::adf.test(Tt)
```

**Discuss:**The DF test confirms that it is stationary as p value \< 0.05 and thus can be used for further analysis.This is after doing double differentiation.It is noteworthy that the stationary signal (top left) generates few significant lags that are larger than the ACF's confidence interval (blue dotted line, bottom left). In contrast, practically all delays in the time series with a trend (top right) surpass the ACF's confidence range (bottom right). Qualitatively, we can observe and infer from the ACFs that the signal on the left is steady (due to the lags that die out) whereas the signal on the right is not (since later lags exceed the confidence interval).

### Specification of the Model

We can create the SARMA model as SARMA(,0,)X(0) based on the previous study  

If there hasn't been any differentiation, we can label it as zero. With the first parameter being PACF and the second being ACF, the first component of multiplication is the non-seasonal part.

The SARMA model's seasonal component follows a similar approach. Since this model has a larger value than the prior SARMA model, it cannot be used. We can utilize the GARCH model and test to see whether the AIC value is better along with the ARMA model as well by omitting the seasonal element as the seasonality pattern is not guaranteed. Generalized Auto-Regressive Conditional Heteroskedasticity models, or GARCH models, can be abbreviated. The GARCH model is commonly used, to estimate value returns for stocks and other financial instruments where trends are unknown. In order to improved the AIC values, we are testing in our case study. Utilizing rugarch, we'll apply the seasonal ARMA-GARCH model.\
Since the data is stationary, we go about finding the p and q values from ACF and PACF plots or use auto.arima() in R.

```{r}
auto.arima(Time_Series)
```
**Discuss:**As we are not differencing the model we can consider ARMA(2,0,3) has the best model. Which is the best *p* and *q* value also found from the ACF and PACF plots.

**Residual Analysis**

**Discuss:**From the above time series plot we can conclude that, the trend within the year values for 1960,2016 and 2020 are similar. We can observe that during start of the year in January the unemployment rate increases and becomes constant during February, March and then decreases sharply post April. Then in mid of the year it increases to a certain level and attains constant until late/end of the year. Clearly we can see some pattern when we do time series plot within a single year. It can be concluded that unemployment rate is higher during winter months and decreased post April which is summer season. Thus the seasonal aspect can be clearly understood.\

### **Modeling and Parameter estimation**

\
Where the **ARIMA (PACF, Num_Diffrentation, ACF)** model have the below format for the parameters. Coefficients for various models:

**Discuss:**Based on the different models, we can see that ARIMA(2,2,5) had the least AIC value, sigma\^2 being the least therefore is the best model for given time series. Find the below time series plot for the residuals.

#### **Residual Analysis**

#### **Residual Plot**

#### **Shapiro Test**

#### **Ljung-Box**

**Time-series Forecasting**

**Discuss:**The plot shows the forecasting to plot for the next 20 values which is shown by the blue region.

```{r}
#| label: tbl-lm

#| tbl-cap: "Linear regression model for predicting EVI from Time"
tdx.ns <- data.frame(time = c(1:length(Time_Series)), trend = Time_Series - tdx.dcp$time.series[,1])
summary <- summary(lm(formula = trend ~ time, data = tdx.ns))
summary
```

```{r}
plot(tdx.ns)
abline(a = summary$coefficients[1,1], b = summary$coefficients[2,1], col = 'blue')
```
```{r,warning=FALSE}
ggdensity(Time_Series,fill = "#0073C2FF",color ="#0073C2FF",add = "mean",rug = TRUE)
```
```{r}
plot(evi.hw <- forecast::hw(y = Time_Series, h = 12, damped = T))
```
